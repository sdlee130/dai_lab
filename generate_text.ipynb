{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bb97b1-3726-4e51-b8a3-d67fbc7ee52c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version             \n",
      "------------------------- --------------------\n",
      "-ransformers              4.45.2              \n",
      "accelerate                0.29.1              \n",
      "aiohttp                   3.9.3               \n",
      "aiosignal                 1.3.1               \n",
      "annotated-types           0.6.0               \n",
      "anyio                     4.3.0               \n",
      "appdirs                   1.4.4               \n",
      "apturl                    0.5.2               \n",
      "argon2-cffi               23.1.0              \n",
      "argon2-cffi-bindings      21.2.0              \n",
      "asttokens                 2.4.1               \n",
      "async-lru                 2.0.4               \n",
      "async-timeout             4.0.3               \n",
      "attrs                     23.2.0              \n",
      "Babel                     2.14.0              \n",
      "backcall                  0.2.0               \n",
      "bcrypt                    3.1.7               \n",
      "beautifulsoup4            4.12.3              \n",
      "bitsandbytes              0.42.0              \n",
      "bleach                    6.1.0               \n",
      "blinker                   1.4                 \n",
      "Brlapi                    0.7.0               \n",
      "cattrs                    23.2.3              \n",
      "certifi                   2019.11.28          \n",
      "cffi                      1.16.0              \n",
      "chardet                   3.0.4               \n",
      "charset-normalizer        3.3.2               \n",
      "click                     8.1.7               \n",
      "colorama                  0.4.3               \n",
      "comm                      0.2.1               \n",
      "command-not-found         0.3                 \n",
      "cryptography              2.8                 \n",
      "cupshelpers               1.0                 \n",
      "datasets                  3.0.1               \n",
      "dbus-python               1.2.16              \n",
      "debugpy                   1.8.1               \n",
      "decorator                 5.1.1               \n",
      "deepspeed                 0.13.4              \n",
      "defer                     1.0.6               \n",
      "defusedxml                0.7.1               \n",
      "dill                      0.3.6               \n",
      "distro                    1.4.0               \n",
      "distro-info               0.23ubuntu1         \n",
      "docker-pycreds            0.4.0               \n",
      "docstring-parser          0.16                \n",
      "duplicity                 0.8.12.0            \n",
      "einops                    0.7.0               \n",
      "entrypoints               0.3                 \n",
      "eval-type-backport        0.2.0               \n",
      "exceptiongroup            1.2.0               \n",
      "executing                 2.0.1               \n",
      "fasteners                 0.14.1              \n",
      "fastjsonschema            2.19.1              \n",
      "filelock                  3.13.1              \n",
      "flash-attn                2.3.5               \n",
      "frozenlist                1.4.1               \n",
      "fsspec                    2024.2.0            \n",
      "future                    0.18.2              \n",
      "gitdb                     4.0.11              \n",
      "GitPython                 3.1.42              \n",
      "h11                       0.14.0              \n",
      "hjson                     3.1.0               \n",
      "httpcore                  1.0.4               \n",
      "httplib2                  0.14.0              \n",
      "httpx                     0.27.0              \n",
      "huggingface-hub           0.25.2              \n",
      "idna                      2.8                 \n",
      "importlib-metadata        7.0.1               \n",
      "importlib-resources       6.1.2               \n",
      "ipdb                      0.13.13             \n",
      "ipykernel                 6.29.4              \n",
      "ipython                   8.12.3              \n",
      "ipywidgets                8.1.2               \n",
      "jedi                      0.19.1              \n",
      "Jinja2                    3.1.3               \n",
      "joblib                    1.4.2               \n",
      "json5                     0.9.20              \n",
      "jsonschema                4.21.1              \n",
      "jsonschema-specifications 2023.12.1           \n",
      "jupyter                   1.0.0               \n",
      "jupyter-client            8.6.0               \n",
      "jupyter-console           6.6.3               \n",
      "jupyter-core              5.7.1               \n",
      "jupyter-events            0.9.0               \n",
      "jupyter-lsp               2.2.3               \n",
      "jupyter-server            2.12.5              \n",
      "jupyter-server-terminals  0.5.2               \n",
      "jupyterlab                4.1.2               \n",
      "jupyterlab-pygments       0.3.0               \n",
      "jupyterlab-server         2.25.3              \n",
      "jupyterlab-widgets        3.0.10              \n",
      "keyring                   18.0.1              \n",
      "language-selector         0.1                 \n",
      "launchpadlib              1.10.13             \n",
      "lazr.restfulclient        0.14.2              \n",
      "lazr.uri                  1.0.3               \n",
      "lockfile                  0.12.2              \n",
      "louis                     3.12.0              \n",
      "macaroonbakery            1.3.1               \n",
      "Mako                      1.1.0               \n",
      "markdown-it-py            3.0.0               \n",
      "MarkupSafe                2.1.5               \n",
      "matplotlib-inline         0.1.6               \n",
      "mdurl                     0.1.2               \n",
      "mistune                   3.0.2               \n",
      "monotonic                 1.5                 \n",
      "mpmath                    1.3.0               \n",
      "msgpack                   1.0.8               \n",
      "multidict                 6.0.5               \n",
      "multiprocess              0.70.16             \n",
      "nbclient                  0.9.0               \n",
      "nbconvert                 7.16.1              \n",
      "nbformat                  5.9.2               \n",
      "nest-asyncio              1.6.0               \n",
      "netifaces                 0.10.4              \n",
      "networkx                  3.1                 \n",
      "ninja                     1.11.1.1            \n",
      "notebook                  7.1.1               \n",
      "notebook-shim             0.2.4               \n",
      "numpy                     1.24.4              \n",
      "nvidia-cublas-cu12        12.1.3.1            \n",
      "nvidia-cuda-cupti-cu12    12.1.105            \n",
      "nvidia-cuda-nvrtc-cu12    12.1.105            \n",
      "nvidia-cuda-runtime-cu12  12.1.105            \n",
      "nvidia-cudnn-cu12         8.9.2.26            \n",
      "nvidia-cufft-cu12         11.0.2.54           \n",
      "nvidia-curand-cu12        10.3.2.106          \n",
      "nvidia-cusolver-cu12      11.4.5.107          \n",
      "nvidia-cusparse-cu12      12.1.0.106          \n",
      "nvidia-nccl-cu12          2.19.3              \n",
      "nvidia-nvjitlink-cu12     12.3.101            \n",
      "nvidia-nvtx-cu12          12.1.105            \n",
      "oauthlib                  3.1.0               \n",
      "olefile                   0.46                \n",
      "overrides                 7.7.0               \n",
      "packaging                 23.2                \n",
      "pandas                    2.0.3               \n",
      "pandocfilters             1.5.1               \n",
      "paramiko                  2.6.0               \n",
      "parso                     0.8.3               \n",
      "peft                      0.4.0               \n",
      "pexpect                   4.6.0               \n",
      "pickleshare               0.7.5               \n",
      "Pillow                    7.0.0               \n",
      "pip                       20.0.2              \n",
      "pkg-resources             0.0.0               \n",
      "pkgutil-resolve-name      1.3.10              \n",
      "platformdirs              4.2.0               \n",
      "prometheus-client         0.20.0              \n",
      "prompt-toolkit            3.0.43              \n",
      "protobuf                  3.20.1              \n",
      "psutil                    5.9.8               \n",
      "ptyprocess                0.7.0               \n",
      "pure-eval                 0.2.2               \n",
      "py-cpuinfo                9.0.0               \n",
      "pyarrow                   15.0.0              \n",
      "pyarrow-hotfix            0.6                 \n",
      "pycairo                   1.16.2              \n",
      "pycparser                 2.21                \n",
      "pycups                    1.9.73              \n",
      "pydantic                  2.6.3               \n",
      "pydantic-core             2.16.3              \n",
      "pygments                  2.17.2              \n",
      "PyGObject                 3.36.0              \n",
      "PyJWT                     1.7.1               \n",
      "pymacaroons               0.13.0              \n",
      "PyNaCl                    1.3.0               \n",
      "pynvml                    11.5.0              \n",
      "pyRFC3339                 1.1                 \n",
      "python-apt                2.0.1+ubuntu0.20.4.1\n",
      "python-dateutil           2.9.0.post0         \n",
      "python-debian             0.1.36ubuntu1       \n",
      "python-json-logger        2.0.7               \n",
      "python-rapidjson          1.16                \n",
      "pytz                      2024.1              \n",
      "pyxdg                     0.26                \n",
      "PyYAML                    5.3.1               \n",
      "pyzmq                     25.1.2              \n",
      "qtconsole                 5.5.1               \n",
      "QtPy                      2.4.1               \n",
      "ray                       2.9.3               \n",
      "referencing               0.33.0              \n",
      "regex                     2023.12.25          \n",
      "reportlab                 3.5.34              \n",
      "requests                  2.32.3              \n",
      "requests-unixsocket       0.2.0               \n",
      "rfc3339-validator         0.1.4               \n",
      "rfc3986-validator         0.1.1               \n",
      "rich                      13.7.1              \n",
      "rpds-py                   0.18.0              \n",
      "safetensors               0.4.5               \n",
      "scikit-learn              1.3.2               \n",
      "scipy                     1.10.1              \n",
      "SecretStorage             2.3.1               \n",
      "Send2Trash                1.8.2               \n",
      "sentencepiece             0.1.99              \n",
      "sentry-sdk                1.40.6              \n",
      "setproctitle              1.3.3               \n",
      "setuptools                44.0.0              \n",
      "shtab                     1.7.1               \n",
      "simplejson                3.16.0              \n",
      "six                       1.14.0              \n",
      "smmap                     5.0.1               \n",
      "sniffio                   1.3.1               \n",
      "soupsieve                 2.5                 \n",
      "ssh-import-id             5.10                \n",
      "stack-data                0.6.3               \n",
      "sympy                     1.12                \n",
      "systemd-python            234                 \n",
      "tabulate                  0.9.0               \n",
      "terminado                 0.18.0              \n",
      "threadpoolctl             3.5.0               \n",
      "tinycss2                  1.2.1               \n",
      "tokenizers                0.20.1              \n",
      "tomli                     2.0.1               \n",
      "torch                     2.1.0+cu121         \n",
      "torchaudio                2.1.0+cu121         \n",
      "torchtyping               0.1.4               \n",
      "torchvision               0.16.0+cu121        \n",
      "tornado                   6.4                 \n",
      "tqdm                      4.66.5              \n",
      "traitlets                 5.14.1              \n",
      "transformers              4.45.2              \n",
      "triton                    2.1.0               \n",
      "tritonclient              2.43.0              \n",
      "trl                       0.8.1               \n",
      "trlx                      0.7.0               \n",
      "typeguard                 4.1.5               \n",
      "typing-extensions         4.10.0              \n",
      "tyro                      0.8.4               \n",
      "tzdata                    2024.1              \n",
      "ubuntu-advantage-tools    8001                \n",
      "ubuntu-drivers-common     0.0.0               \n",
      "ufw                       0.36                \n",
      "unattended-upgrades       0.1                 \n",
      "urllib3                   2.2.1               \n",
      "usb-creator               0.3.7               \n",
      "wadllib                   1.3.3               \n",
      "wandb                     0.16.3              \n",
      "wcwidth                   0.2.13              \n",
      "webencodings              0.5.1               \n",
      "websocket-client          1.7.0               \n",
      "wheel                     0.34.2              \n",
      "widgetsnbextension        4.0.10              \n",
      "xkit                      0.0.0               \n",
      "xxhash                    3.4.1               \n",
      "yarl                      1.9.4               \n",
      "zipp                      3.17.0              \n"
     ]
    }
   ],
   "source": [
    "!pip list  # 라이브러리 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7807b58-fe08-4217-b3cc-002b2b5a4954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 실행 중 warning 무시 + wandb라는 시각화 라이브러리 기능 끄기\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a05aa4-75e9-41db-b7bd-502780c3b07c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0d609ee9be4b4d8697cd462e450062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14e79fbf85c4748991db1da16ebb7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 3000\n",
      "{'text': \" Once upon a time, there were three friends named Alex, Jamie, and Taylor who decided to go on a scuba diving adventure in the beautiful blue waters of the Caribbean Sea. Although none of them had much experience diving, they did extensive research on the necessary equipment, safety precautions, and communication techniques required for an enjoyable dive.\\n\\nAlex was adventurous and outgoing, while Jamie was cautious yet curious. Taylor, on the other hand, tended to be reckless and impulsive, which sometimes caused friction among the trio. However, they all agreed on practicing good communication during the dive, especially since they would explore depths up to 60 feet below sea level.\\n\\nBefore descending into the ocean, the team reviewed various hand signals that could help them convey essential information without speaking. They practiced gestures indicating 'OK', 'Up', 'Down', 'Look', 'Stop', and 'Problem'. These basic signals ensured that everyone understood what message the others intended to send.\\n\\nAs they began their descent, everything seemed perfect – bright sunshine filtering down from above, colorful fish swimming around them, and coral reefs teeming with life. But soon enough, they encountered several challenges due to poor visibility. To overcome this issue, they brought along powerful LED flashlights to aid in signaling and communicating. With pre-agreed light codes, they managed to stay together even when the environment became murky.\\n\\nDuring the course of the exploration, Taylor spotted something unusual - a sunken treasure chest! Eager to claim it as his own discovery, he rushed towards the artifact without informing the rest of the group. Noticing his absence, Alex and Jamie searched for him using their hand signals and light codes. After locating the area where Taylor disappeared, they found him struggling to lift the heavy chest alone.\\n\\nTaylor ignored Alex and Jamie's repeated attempts to dissuade him from lifting the chest by himself, insisting that he didn't need any assistance. Ignoring the buddies' advice led to a series of unfortunate events; first, the rope tied to the chest got tangled in the nearby corals causing damage. Secondly, while trying to free the trapped rope, Taylor lost control over his buoyancy and started ascending rapidly, risking decompression sickness.\\n\\nRealizing the gravity of the situation, Alex quickly swam upwards and grabbed onto Taylor, stabilizing his ascent rate. Meanwhile, Jamie stayed behind to untangle the rope from the damaged coral. Back at the surface, the entire team took a moment to reflect on the incident and its implications.\\n\\nThrough this shared experience, they learned valuable lessons about trust, collaboration, and responsible decision making. They realized how crucial effective communication was, not just in extreme scenarios like scuba diving but also in everyday life. By listening to each other and working together, they avoided potential disaster and strengthened their bond further.\\n\\nFrom then on, whenever faced with challenging situations, whether underwater or back home, the trio always remembered their unforgettable diving adventure. It served as a constant reminder of the significance of empathy, ethical conduct, and problem-solving skills needed to navigate through life successfully.\", 'prompt': 'Write a story that explores a situation slightly related to this text snippet:\\n“Can you describe the proper diving signals and communication methods?\\nI don\\'t have the experiences of a scuba diver, but i have done some research on this. here are some of the proper diving signals and communication methods:\\n\\n1. hand signals: divers use hand signals to communicate with each other underwater. these signals are simple gestures that indicate messages like \"okay,\" \"up,\" \"down,\" \"look,\" \"stop,\" or \"problem.\"\\n2. light signals: in low visibility conditions, divers use lights to communicate with each other. they use flashlights or strobes to signal messages such as \"follow me,\" \"stop,\" or \"look at me.\"\\n3. sound signals: divers often carry whistles or use underwater noisemakers to communicate with each other. these devices are used to signal warnings, attention-getting, or emergency situations.\\n4. buddy system: the most important form of communication for scuba divers is the buddy system. before entering the water, divers discuss hand signals and establish a plan for underwate”\\n\\nInclude characters with distinct personalities. The story should unfold through their interactions, decisions, and the consequences of their actions. Aim to weave in common sense lessons and social cues, emphasizing the importance of empathy, ethics, and problem-solving.\\nThe narrative should cater to a diverse age group, including at least one dialogue and presenting both positive and negative outcomes.', 'text_token_length': 692, 'seed_data': 'ultrachat', 'format': 'story_life_lessons', 'audience': 'general'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "\n",
    "# huggingface hub에서 데이터셋 가져오기, 여기서는 cosmopedia의 stories에서 3000개만을 가져옴\n",
    "dataset = load_dataset(\"HuggingFaceTB/cosmopedia\", \"stories\", split=\"train[:3000]\") # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67726882-0e21-45b0-806b-4fa58cfcdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction tuning을 할 때 입력으로 줄 형식\n",
    "# instruction 없이 데이터만을 입력으로 주면 원하는 출력을 얻지 못할 확률이 높음\n",
    "\n",
    "def format_instruction(sample):\n",
    "\treturn f\"\"\"### Instruction:\n",
    "You are provided with a prompt. \n",
    "Your task is to generate a coherent and creative continuation of the given prompt, crafting a well-developed story. \n",
    "The story should maintain relevance to the context provided by the prompt \n",
    "and expand upon it with logical and imaginative progression.\n",
    " \n",
    "### Input:\n",
    "{sample['prompt']}\n",
    " \n",
    "### Response:\n",
    "{sample['text']}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf70534-0a39-4981-87b9-1791d03e1f27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "You are provided with a prompt. \n",
      "Your task is to generate a coherent and creative continuation of the given prompt, crafting a well-developed story. \n",
      "The story should maintain relevance to the context provided by the prompt \n",
      "and expand upon it with logical and imaginative progression.\n",
      " \n",
      "### Input:\n",
      "Write an educational story (3-5 paragraphs) targeted at young children using simple words. The story should be inspired from this text snippet: \n",
      "“Q:I have been preparing our house for the market and in doing so, I have gotten rid of a lot of stuff! I am definitely the hoarder in our house. My husband could live out of two bags, use about five kitchen items each year, and doesn’t gather anything for future use or hang on to much for sentimental value. (Which probably means the items he has hung on to mean a whole lot more!) I am always tucking something away here or stashing materials there…all in preparation for “some day.” It’s also part of the teacher in me. Do you know many teachers that don’t have a ton of stuff or utilize every bit of storage available? But, over the last several years, I’ve been fairly good about going through things every six months and weeding out a little here and a little there. Today I’ll be sharing six simple ways to declutter your home and why you should! GIVE THINGS AWAY It’s nice to make money, but sometimes you come across something that you really think someone else could use and you don’t want ”\n",
      "\n",
      "The story doesn’t have to be addressing everything in the snippet, it is there just for inspiration.\n",
      "The story should have the following features: \n",
      "- Science integration: embed basic science concepts within the story, explaining them through the characters' adventures and discoveries. For example, if the story includes a scene where characters are looking at the sky, you could have them wonder why it's blue and explain the physics behind in grade school level.\n",
      "- Dialogue: include at least one dialogue and insightful conversation.\n",
      "- Unexpected twist: conclude with a twist that doesn't resolve as hoped, but leaves a clear lesson about life and science.\n",
      "Do not start with classic sentences like \"Once upon a time\", be creative.\n",
      " \n",
      "### Response:\n",
      " Once there were two best friends, Timmy and Sally. They loved playing together and learning new things. One sunny afternoon, they decided to clean up their clubhouse to make room for more toys and books. As they sorted through piles of games and stuffed animals, Sally picked up a beautiful seashell.\n",
      "\n",
      "\"Look at this shell, Tim!\" she exclaimed. \"It reminds me of our trip to the beach last summer.\"\n",
      "\n",
      "Tim smiled. \"That was fun! You know, you can give that shell to someone who hasn't seen the ocean before. Maybe they would love having a piece of the sea in their home.\"\n",
      "\n",
      "Sally thought for a moment. She realized that giving her special shell away would help bring joy to another person while making space in her clubhouse. This made her excited!\n",
      "\n",
      "As they continued cleaning, they discovered old puzzles, broken crayons, and clothes they had grown out of. With each item, they asked themselves three questions – do I need this, does it work properly, and will someone else benefit from it? If the answer was no, then into the 'giveaway box' it went!\n",
      "\n",
      "Finally, after hours of organizing and laughing, their clubhouse looked amazing - spacious and filled only with items they truly needed and enjoyed. Just then, Mrs. Johnson, their neighbor, walked by. Seeing all the treasures in the giveaway box, she said, \"Wow, what a wonderful collection! May I take some of these things for my grandchildren?\"\n",
      "\n",
      "Timmy and Sally felt proud and happy knowing that their unused items would now become cherished possessions for others. Then, Timmy turned to Sally and suggested, \"Let's challenge ourselves to fill this box again in three months! We might find even more things we don't need.\"\n",
      "\n",
      "But when they woke up the next morning, their newly organized clubhouse faced an unexpected disaster. Heavy rain poured throughout the night, seeping into their precious play area and ruining some of their favorite toys. Their hearts sank, realizing how quickly plans can change due to natural events. Even though they lost some belongings, they learned valuable lessons about letting go and understanding the importance of needs vs wants. And soon enough, they started rebuilding their clubhouse stronger than ever, eagerly anticipating their next cleanup adventure.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instruction 형식에 맞춰진 데이터 예시\n",
    "\n",
    "from random import randrange\n",
    "\n",
    "print(format_instruction(dataset[randrange(len(dataset))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eebb7cfe-66ad-4fc6-b55f-6c11bb8d2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning할 모델 불러오기\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from accelerate import PartialState\n",
    " \n",
    "use_flash_attention = False\n",
    " \n",
    "# huggingface hub에서 사전학습된 모델 불러오기\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    " \n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    use_cache=False,\n",
    "    use_flash_attention_2=use_flash_attention,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab726252-3c38-40a5-9634-9f7ad84198ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361821120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 크기 확인\n",
    "\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4e6f88-8369-43ce-ad18-5b0256b9f537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "targetmodule=[\n",
    "  \"q_proj\",\n",
    "  \"k_proj\",\n",
    "  \"v_proj\",\n",
    "  \"o_proj\",\n",
    "  \"gate_proj\",\n",
    "  \"up_proj\",\n",
    "  \"down_proj\",\n",
    "  \"lm_head\",\n",
    "]\n",
    "\n",
    "# LoRA config based on QLoRA paper\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=targetmodule,\n",
    ")\n",
    " \n",
    " \n",
    "# prepare model for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "from transformers import TrainingArguments\n",
    " \n",
    "args = TrainingArguments(\n",
    "    output_dir=dir_name, # checkpoint나 학습 완료된 모델 저장할 경로\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1 if use_flash_attention else 1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    disable_tqdm=False # disable tqdm since with packing values are in correct\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e62cfc5-3b57-4c01-8c00-55ebe830462d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    " \n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=2048,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    formatting_func=format_instruction,\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16adf336-e541-4881-8699-a1c20ef44bdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='507' max='507' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [507/507 42:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.983700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.876200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.533800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.433900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.409900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.387300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.387100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.367900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.389400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.381100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.364700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.355200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.325300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.359400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.370400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.368700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.371200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.320100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.336600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.338800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.332300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.326100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.377700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.318100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.332200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train\n",
    "trainer.train() # there will not be a progress bar since tqdm is disabled\n",
    " \n",
    "# save model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25e2223c-8ca1-4c9b-91b2-955ad76a0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_flash_attention:\n",
    "    from utils.llama_patch import unplace_flash_attn_with_attn\n",
    "    unplace_flash_attn_with_attn()\n",
    " \n",
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    " \n",
    "args.output_dir = dir_name # checkpoint나 학습 완료된 모델 저장된 경로\n",
    " \n",
    "# 저장된 모델 불러오기\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    args.output_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95d3ff76-c2bb-4225-b5a9-c80f226f6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning이 아닌 text generation을 위한 instruction format\n",
    "\n",
    "def format_instruction_inference(sample):\n",
    "    return f\"\"\"### Instruction:\n",
    "You are provided with a prompt. \n",
    "Your task is to generate a coherent and creative continuation of the given prompt, crafting a well-developed story. \n",
    "The story should maintain relevance to the context provided by the prompt \n",
    "and expand upon it with logical and imaginative progression.\n",
    " \n",
    "### Input:\n",
    "{sample['prompt']}\n",
    " \n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8112e7c-3623-4fe8-8adb-919806aa52f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec74f824d0d24237a2a08609dbc8e809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bea2ea9d00641c4ba44cfca2a7fc9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:00:45<00:00, 36.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    " \n",
    "# Load dataset from the hub and get a sample\n",
    "dataset = load_dataset(\"HuggingFaceTB/cosmopedia\", \"stories\", split=\"train[3000:3100]\")\n",
    "\n",
    "test_result = []\n",
    "\n",
    "# text generation\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    prompt = format_instruction_inference(dataset[i])\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=1024, do_sample=True, top_p=0.9,temperature=0.9)\n",
    "    gen_story = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]\n",
    "    test_result.append(gen_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33bb0f61-a626-40b4-ae6e-c8c4710a1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 text와 원 데이터셋에 있는 text를 함께 dataframe으로 저장\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['prompt'] = dataset['prompt']\n",
    "result['gen_story'] = test_result\n",
    "result['ground_truth'] = dataset['text']\n",
    "\n",
    "result.to_csv(\"./result/\"+dir_name+\".csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f3822-6eef-4423-8532-73a40e1715a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 torch",
   "language": "python",
   "name": "python3-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
